{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Eran-BA/ART/blob/main/dcmrta_coalition_postrun.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9IGJY0SW_ND"
      },
      "source": [
        "# DCMRTA Coalition Formation with PoT (Pointer over Heads)\n",
        "\n",
        "Supervised learning for **coalition formation** using the **official DCMRTA benchmark**.\n",
        "\n",
        "## Key Innovation: Learnable Coalition Formation\n",
        "\n",
        "Using the official DCMRTA benchmark (ICRA 2024):\n",
        "- **20 robots, 50 tasks** per problem\n",
        "- **Coalition size**: 1-5 robots per task\n",
        "- **Greedy solution targets** for supervised learning\n",
        "\n",
        "## Architecture: HybridHRM (identical to Scheduling)\n",
        "\n",
        "Same PoT architecture with coalition-specific output:\n",
        "- **Two-timescale reasoning**: H-level (slow/global) + L-level (fast/local)\n",
        "- **Coalition output**: Sigmoid scores for (task, robot) pairs\n",
        "- **Top-K selection**: Pick K robots based on coalition size requirement\n",
        "\n",
        "| Component | Scheduling | Coalition |\n",
        "|-----------|------------|----------|\n",
        "| Output | Softmax logits | **Sigmoid scores** |\n",
        "| Selection | argmax (1) | **Top-K** |\n",
        "| Loss | Cross-entropy | **Binary CE** |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0i7UNoMW_NE",
        "outputId": "a8892c7d-e606-4c1c-897d-b8ce67e58ba2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîß Setting up for Google Colab...\n",
            "‚úì GitHub token loaded\n",
            "üì¶ Installing dependencies...\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m29.8/29.8 MB\u001b[0m \u001b[31m90.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m323.3/323.3 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 6.33.4 which is incompatible.\n",
            "tensorflow 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.4 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.33.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m‚úì W&B API key loaded\n",
            "üì• Cloning SymbolicMultiRobotTaskAllocator...\n",
            "Cloning into '/content/SymbolicMultiRobotTaskAllocator'...\n",
            "remote: Enumerating objects: 193, done.\u001b[K\n",
            "remote: Counting objects: 100% (193/193), done.\u001b[K\n",
            "remote: Compressing objects: 100% (105/105), done.\u001b[K\n",
            "remote: Total 193 (delta 102), reused 146 (delta 57), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (193/193), 3.94 MiB | 8.59 MiB/s, done.\n",
            "Resolving deltas: 100% (102/102), done.\n",
            "üì• Cloning PoT...\n",
            "Cloning into '/content/PoT'...\n",
            "remote: Enumerating objects: 474, done.\u001b[K\n",
            "remote: Counting objects: 100% (474/474), done.\u001b[K\n",
            "remote: Compressing objects: 100% (439/439), done.\u001b[K\n",
            "remote: Total 474 (delta 49), reused 301 (delta 24), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (474/474), 2.07 MiB | 12.63 MiB/s, done.\n",
            "Resolving deltas: 100% (49/49), done.\n",
            "üì• Cloning DCMRTA (official benchmark)...\n",
            "Cloning into '/content/DCMRTA'...\n",
            "remote: Enumerating objects: 389, done.\u001b[K\n",
            "remote: Counting objects: 100% (389/389), done.\u001b[K\n",
            "remote: Compressing objects: 100% (190/190), done.\u001b[K\n",
            "remote: Total 389 (delta 195), reused 386 (delta 195), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (389/389), 29.25 MiB | 41.37 MiB/s, done.\n",
            "Resolving deltas: 100% (195/195), done.\n",
            "‚úì Colab setup complete!\n",
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# üöÄ COLAB SETUP - Run this cell first\n",
        "#\n",
        "# Add your GitHub token to Colab Secrets:\n",
        "#   1. Click üîë icon in left sidebar\n",
        "#   2. Add secret: GITHUB_TOKEN = your PAT\n",
        "#   3. Enable 'Notebook access'\n",
        "\n",
        "import sys\n",
        "import os\n",
        "\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    print(\"üîß Setting up for Google Colab...\")\n",
        "    os.chdir('/content')\n",
        "\n",
        "    from google.colab import userdata\n",
        "    try:\n",
        "        GITHUB_TOKEN = userdata.get('GITHUB_TOKEN')\n",
        "        print(\"‚úì GitHub token loaded\")\n",
        "    except:\n",
        "        raise ValueError(\"‚ùå Add GITHUB_TOKEN to Colab Secrets\")\n",
        "\n",
        "    GITHUB_USER = \"Eran-BA\"\n",
        "    !git config --global url.\"https://{GITHUB_TOKEN}@github.com/\".insteadOf \"https://github.com/\"\n",
        "\n",
        "    print(\"üì¶ Installing dependencies...\")\n",
        "    !pip install torch tqdm matplotlib numpy wandb seaborn pyyaml ortools -q\n",
        "\n",
        "    try:\n",
        "        WANDB_KEY = userdata.get('WANDB_API_KEY')\n",
        "        os.environ['WANDB_API_KEY'] = WANDB_KEY\n",
        "        print(\"‚úì W&B API key loaded\")\n",
        "    except:\n",
        "        print(\"‚ö†Ô∏è WANDB_API_KEY not found\")\n",
        "\n",
        "    # Clone SymbolicMultiRobotTaskAllocator\n",
        "    if os.path.exists('/content/SymbolicMultiRobotTaskAllocator/.git'):\n",
        "        print(\"üì• Updating SymbolicMultiRobotTaskAllocator...\")\n",
        "        !cd /content/SymbolicMultiRobotTaskAllocator && git pull\n",
        "    else:\n",
        "        print(\"üì• Cloning SymbolicMultiRobotTaskAllocator...\")\n",
        "        !git clone https://{GITHUB_TOKEN}@github.com/{GITHUB_USER}/SymbolicMultiRobotTaskAllocator.git /content/SymbolicMultiRobotTaskAllocator\n",
        "\n",
        "    # Clone PoT\n",
        "    if not os.path.exists('/content/PoT/.git'):\n",
        "        print(\"üì• Cloning PoT...\")\n",
        "        !git clone --depth 1 https://{GITHUB_TOKEN}@github.com/{GITHUB_USER}/PoT.git /content/PoT\n",
        "\n",
        "    # Clone DCMRTA (official benchmark)\n",
        "    if not os.path.exists('/content/DCMRTA/.git'):\n",
        "        print(\"üì• Cloning DCMRTA (official benchmark)...\")\n",
        "        !git clone --depth 1 https://github.com/marmotlab/DCMRTA.git /content/DCMRTA\n",
        "\n",
        "    sys.path.insert(0, '/content/PoT')\n",
        "    sys.path.insert(0, '/content/PoT/src')\n",
        "    sys.path.insert(0, '/content/DCMRTA')\n",
        "    sys.path.insert(0, '/content/SymbolicMultiRobotTaskAllocator')\n",
        "\n",
        "    os.chdir('/content/SymbolicMultiRobotTaskAllocator')\n",
        "    DCMRTA_PATH = '/content/DCMRTA'\n",
        "    print(\"‚úì Colab setup complete!\")\n",
        "else:\n",
        "    print(\"Running locally\")\n",
        "    POT_PATH = '/Users/rnbnrzy/Desktop/PoT'\n",
        "    MRTA_PATH = '/Users/rnbnrzy/Desktop/SymbolicMultiRobotTaskAllocator'\n",
        "    DCMRTA_PATH = '/Users/rnbnrzy/Desktop/DCMRTA'\n",
        "\n",
        "    sys.path.insert(0, POT_PATH)\n",
        "    sys.path.insert(0, f'{POT_PATH}/src')\n",
        "    sys.path.insert(0, DCMRTA_PATH)\n",
        "    sys.path.insert(0, MRTA_PATH)\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "from tqdm.auto import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Using device: {device}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2cTi_m-W_NF"
      },
      "source": [
        "## 1. Load DCMRTA Benchmark Data\n",
        "\n",
        "Using the **official test set** from the DCMRTA paper (ICRA 2024):\n",
        "- 50 environments with 20 robots, 50 tasks each\n",
        "- Coalition sizes: 1-5 robots per task\n",
        "- Pre-computed results for comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281,
          "referenced_widgets": [
            "6268ce987ed1427db079803969576b53",
            "6a6f4e10612b4bf985ac310d66ce005f",
            "ab8c714b3bc54febbde13ec38cef72e1",
            "1f4fbed2eac74561918aefa9672d43a8",
            "538da1ff4b22448d9147d9f1a6e7d4f8",
            "fd73307c44fa4b01826a98d42193667e",
            "ac609466b57545aba2281eb92ad84264",
            "1c7b1f365054482293294b2568da31a3",
            "62e78ddc1c7d419ab595c1e8401437ad",
            "195fdbe2083a401d8bcce4d1e5f6ce62",
            "bcc4ccce265a4f94bf17e3e78e8bb3ec"
          ]
        },
        "id": "P9RYJE6tW_NF",
        "outputId": "0a654e97-67b1-43fa-fb2e-44ff99d806d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• Loading DCMRTA benchmark...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading DCMRTA:   0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6268ce987ed1427db079803969576b53"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä DCMRTA Benchmark:\n",
            "   Environments: 50\n",
            "   Robots per env: 20\n",
            "   Tasks per env: 50\n",
            "\n",
            "üìä Coalition Size Distribution:\n",
            "   Size 1: 532 tasks (21.3%)\n",
            "   Size 2: 467 tasks (18.7%)\n",
            "   Size 3: 490 tasks (19.6%)\n",
            "   Size 4: 490 tasks (19.6%)\n",
            "   Size 5: 521 tasks (20.8%)\n"
          ]
        }
      ],
      "source": [
        "# Load DCMRTA environments\n",
        "from env.task_env import TaskEnv\n",
        "\n",
        "def load_dcmrta_envs(test_set=\"testSet_20A_50T_CONDET\", n_envs=None):\n",
        "    \"\"\"Load DCMRTA environments from official repo.\"\"\"\n",
        "    test_dir = Path(DCMRTA_PATH) / test_set\n",
        "\n",
        "    envs = []\n",
        "    pkl_files = sorted(test_dir.glob(\"env_*.pkl\"))\n",
        "    if n_envs:\n",
        "        pkl_files = pkl_files[:n_envs]\n",
        "\n",
        "    for f in tqdm(pkl_files, desc=\"Loading DCMRTA\"):\n",
        "        env = pickle.load(open(f, 'rb'))\n",
        "        envs.append(env)\n",
        "\n",
        "    return envs\n",
        "\n",
        "# Load all 50 test environments\n",
        "print(\"üì• Loading DCMRTA benchmark...\")\n",
        "envs = load_dcmrta_envs()\n",
        "\n",
        "# Analyze\n",
        "print(f\"\\nüìä DCMRTA Benchmark:\")\n",
        "print(f\"   Environments: {len(envs)}\")\n",
        "print(f\"   Robots per env: {len(envs[0].agent_dic)}\")\n",
        "print(f\"   Tasks per env: {len(envs[0].task_dic)}\")\n",
        "\n",
        "# Coalition size distribution\n",
        "coalition_sizes = []\n",
        "for env in envs:\n",
        "    for task in env.task_dic.values():\n",
        "        coalition_sizes.append(int(task['requirements'][0]))\n",
        "\n",
        "from collections import Counter\n",
        "dist = Counter(coalition_sizes)\n",
        "print(f\"\\nüìä Coalition Size Distribution:\")\n",
        "for size in sorted(dist.keys()):\n",
        "    print(f\"   Size {size}: {dist[size]} tasks ({dist[size]/len(coalition_sizes)*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdYh5RKFW_NF"
      },
      "source": [
        "## 2. Create Dataset\n",
        "\n",
        "Convert DCMRTA environments to PyTorch dataset:\n",
        "- Task features: location (x, y) + coalition size\n",
        "- Robot features: location (x, y) + velocity\n",
        "- Generate training targets using greedy assignment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_nyTN84W_NF",
        "outputId": "c27ca512-3362-4f9d-8236-85e2c6428a98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Dataset:\n",
            "   Train: 40 environments\n",
            "   Test: 10 environments\n"
          ]
        }
      ],
      "source": [
        "class DCMRTADataset(Dataset):\n",
        "    \"\"\"DCMRTA Coalition Formation Dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, envs, n_tasks=50, n_robots=20):\n",
        "        self.envs = envs\n",
        "        self.n_tasks = n_tasks\n",
        "        self.n_robots = n_robots\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.envs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        env = self.envs[idx]\n",
        "\n",
        "        # Task features: [n_tasks, 3] = (x, y, coalition_size/5)\n",
        "        task_features = torch.zeros(self.n_tasks, 3)\n",
        "        coalition_sizes = torch.zeros(self.n_tasks, dtype=torch.long)\n",
        "\n",
        "        for i, task in env.task_dic.items():\n",
        "            if i < self.n_tasks:\n",
        "                task_features[i, 0] = task['location'][0]\n",
        "                task_features[i, 1] = task['location'][1]\n",
        "                task_features[i, 2] = task['requirements'][0] / 5.0\n",
        "                coalition_sizes[i] = int(task['requirements'][0])\n",
        "\n",
        "        # Robot features: [n_robots, 3] = (x, y, velocity)\n",
        "        robot_features = torch.zeros(self.n_robots, 3)\n",
        "        for i, agent in env.agent_dic.items():\n",
        "            if i < self.n_robots:\n",
        "                robot_features[i, 0] = agent['location'][0]\n",
        "                robot_features[i, 1] = agent['location'][1]\n",
        "                robot_features[i, 2] = agent['velocity']\n",
        "\n",
        "        # Greedy targets\n",
        "        targets = self._greedy_assignment(env)\n",
        "\n",
        "        return {\n",
        "            'task_features': task_features,\n",
        "            'robot_features': robot_features,\n",
        "            'coalition_sizes': coalition_sizes,\n",
        "            'targets': targets,\n",
        "        }\n",
        "\n",
        "    def _greedy_assignment(self, env):\n",
        "        \"\"\"Generate greedy coalition assignments.\"\"\"\n",
        "        targets = torch.zeros(self.n_tasks, self.n_robots)\n",
        "\n",
        "        for i, task in env.task_dic.items():\n",
        "            if i >= self.n_tasks:\n",
        "                continue\n",
        "            k = int(task['requirements'][0])\n",
        "            task_loc = np.array(task['location'])\n",
        "\n",
        "            # Find k closest robots\n",
        "            dists = []\n",
        "            for j, agent in env.agent_dic.items():\n",
        "                if j >= self.n_robots:\n",
        "                    continue\n",
        "                d = np.linalg.norm(task_loc - np.array(agent['location']))\n",
        "                dists.append((j, d))\n",
        "            dists.sort(key=lambda x: x[1])\n",
        "\n",
        "            for j, _ in dists[:k]:\n",
        "                targets[i, j] = 1.0\n",
        "\n",
        "        return targets\n",
        "\n",
        "# Split data: 40 train, 10 test\n",
        "train_envs = envs[:40]\n",
        "test_envs = envs[40:]\n",
        "\n",
        "train_dataset = DCMRTADataset(train_envs)\n",
        "test_dataset = DCMRTADataset(test_envs)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8)\n",
        "\n",
        "print(f\"\\nüìä Dataset:\")\n",
        "print(f\"   Train: {len(train_dataset)} environments\")\n",
        "print(f\"   Test: {len(test_dataset)} environments\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDvVdKlpW_NF"
      },
      "source": [
        "## 3. Create Model\n",
        "\n",
        "**CoalitionHybridHRM** - identical architecture to SchedulingHybridHRM with coalition output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ju_Y0GsrW_NF",
        "outputId": "0aa1e20d-9f9e-4082-a3fc-1b17522d3a58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created CoalitionHybridHRM with 8,789,546 parameters\n",
            "\n",
            "‚úÖ Model: CoalitionHybridHRM\n",
            "   Architecture: HybridHRM (identical to Scheduling)\n",
            "   Output: Sigmoid scores for coalition membership\n"
          ]
        }
      ],
      "source": [
        "from src.model import CoalitionHybridHRM, create_coalition_model\n",
        "\n",
        "# Model config (identical to Scheduling)\n",
        "config = {\n",
        "    'd_model': 256,\n",
        "    'd_ctrl': 256,\n",
        "    'd_ff': 512,\n",
        "    'n_heads': 8,\n",
        "    'H_layers': 2,\n",
        "    'L_layers': 2,\n",
        "    'H_cycles': 2,\n",
        "    'L_cycles': 4,\n",
        "    'halt_max_steps': 2,\n",
        "    'dropout': 0.1,\n",
        "    'max_tasks': 50,\n",
        "    'max_robots': 20,\n",
        "    'task_feature_dim': 3,\n",
        "    'robot_feature_dim': 3,\n",
        "}\n",
        "\n",
        "model = create_coalition_model(config, device)\n",
        "\n",
        "print(f\"\\n‚úÖ Model: CoalitionHybridHRM\")\n",
        "print(f\"   Architecture: HybridHRM (identical to Scheduling)\")\n",
        "print(f\"   Output: Sigmoid scores for coalition membership\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQ_tP9LhW_NF"
      },
      "source": [
        "## 4. Training\n",
        "\n",
        "Supervised training with binary cross-entropy loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5o2vC2pW_NF",
        "outputId": "6e3e49d9-0ddf-4976-91f9-855c8cdc5ebd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Training CoalitionHybridHRM for 50 epochs on cuda\n",
            "============================================================\n",
            "Epoch   1 | Loss: 0.5181 | Coalition Acc: 33.0% | Size Match: 100.0% ‚úì NEW BEST\n",
            "Epoch  10 | Loss: 0.3693 | Coalition Acc: 77.6% | Size Match: 100.0% ‚úì NEW BEST\n",
            "Epoch  20 | Loss: 0.0811 | Coalition Acc: 100.0% | Size Match: 100.0% ‚úì NEW BEST\n",
            "Epoch  30 | Loss: 0.0428 | Coalition Acc: 100.0% | Size Match: 100.0% \n",
            "Epoch  40 | Loss: 0.0367 | Coalition Acc: 100.0% | Size Match: 100.0% \n",
            "Epoch  50 | Loss: 0.0361 | Coalition Acc: 100.0% | Size Match: 100.0% \n",
            "============================================================\n",
            "\n",
            "üèÜ Best Coalition Accuracy: 100.0%\n"
          ]
        }
      ],
      "source": [
        "def train_epoch(model, loader, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in loader:\n",
        "        task_features = batch['task_features'].to(device)\n",
        "        robot_features = batch['robot_features'].to(device)\n",
        "        targets = batch['targets'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        logits = model(task_features, robot_features)\n",
        "        loss = F.binary_cross_entropy_with_logits(logits, targets)\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "\n",
        "def evaluate(model, loader, device):\n",
        "    model.eval()\n",
        "\n",
        "    coalition_accs = []\n",
        "    size_matches = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            task_features = batch['task_features'].to(device)\n",
        "            robot_features = batch['robot_features'].to(device)\n",
        "            coalition_sizes = batch['coalition_sizes'].to(device)\n",
        "            targets = batch['targets'].to(device)\n",
        "\n",
        "            coalitions = model.predict_coalitions(\n",
        "                task_features, robot_features, coalition_sizes\n",
        "            )\n",
        "\n",
        "            B, T, R = targets.shape\n",
        "            for b in range(B):\n",
        "                for t in range(T):\n",
        "                    if coalition_sizes[b, t] > 0:\n",
        "                        pred = set(coalitions[b][t])\n",
        "                        true = set(r for r in range(R) if targets[b, t, r] > 0.5)\n",
        "\n",
        "                        inter = len(pred & true)\n",
        "                        union = len(pred | true)\n",
        "                        coalition_accs.append(inter / union if union > 0 else 0)\n",
        "                        size_matches.append(1.0 if len(pred) == len(true) else 0.0)\n",
        "\n",
        "    return {\n",
        "        'coalition_acc': np.mean(coalition_accs) if coalition_accs else 0,\n",
        "        'size_match': np.mean(size_matches) if size_matches else 0,\n",
        "    }\n",
        "\n",
        "\n",
        "# Training\n",
        "EPOCHS = 50\n",
        "LR = 3e-4\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=0.01)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, EPOCHS)\n",
        "\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Training CoalitionHybridHRM for {EPOCHS} epochs on {device}\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "best_acc = 0\n",
        "for epoch in range(EPOCHS):\n",
        "    train_loss = train_epoch(model, train_loader, optimizer, device)\n",
        "\n",
        "    if (epoch + 1) % 10 == 0 or epoch == 0:\n",
        "        metrics = evaluate(model, test_loader, device)\n",
        "\n",
        "        status = \"\"\n",
        "        if metrics['coalition_acc'] > best_acc:\n",
        "            best_acc = metrics['coalition_acc']\n",
        "            status = \"‚úì NEW BEST\"\n",
        "\n",
        "        print(f\"Epoch {epoch+1:3d} | Loss: {train_loss:.4f} | \"\n",
        "              f\"Coalition Acc: {metrics['coalition_acc']*100:.1f}% | \"\n",
        "              f\"Size Match: {metrics['size_match']*100:.1f}% {status}\")\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"\\nüèÜ Best Coalition Accuracy: {best_acc*100:.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVm46XLBW_NF"
      },
      "source": [
        "## 5. Comparison with Paper Benchmarks\n",
        "\n",
        "Compare our results with the official DCMRTA paper results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Huvl5a22W_NF",
        "outputId": "4adb7157-c9db-40d5-e0f8-0de27dab7ce3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "üìä DCMRTA PAPER BENCHMARK RESULTS\n",
            "============================================================\n",
            "\n",
            "REINFORCE_LF.csv:\n",
            "   Success Rate: 100.0%\n",
            "   Avg Makespan: 34.83\n",
            "\n",
            "REINFORCE_IA.csv:\n",
            "   Success Rate: 100.0%\n",
            "   Avg Makespan: 35.02\n",
            "\n",
            "OR-Tools.csv:\n",
            "   Success Rate: 100.0%\n",
            "   Avg Makespan: 42.00\n",
            "\n",
            "CTAS-D_300s.csv:\n",
            "   Success Rate: 100.0%\n",
            "   Avg Makespan: 36.91\n",
            "\n",
            "============================================================\n",
            "üìä OUR RESULTS (PoT CoalitionHybridHRM)\n",
            "============================================================\n",
            "\n",
            "üéØ Coalition Accuracy: 100.0%\n",
            "üìè Size Match: 100.0%\n",
            "\n",
            "============================================================\n",
            "üìã COMPARISON\n",
            "============================================================\n",
            "\n",
            "Method                                  Metric\n",
            "--------------------------------------------------\n",
            "REINFORCE_LF (paper)      100% success, 34.8 makespan\n",
            "OR-Tools (paper)          100% success, 42.0 makespan\n",
            "Ours (PoT)                100.0% coalition acc\n",
            "\n",
            "============================================================\n",
            "Note: Paper reports success_rate and makespan (routing metric).\n",
            "We report coalition accuracy (correct robot selection).\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Load official paper results\n",
        "import pandas as pd\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üìä DCMRTA PAPER BENCHMARK RESULTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "results_dir = Path(DCMRTA_PATH) / \"testSet_20A_50T_CONDET\"\n",
        "\n",
        "for csv_file in ['REINFORCE_LF.csv', 'REINFORCE_IA.csv', 'OR-Tools.csv', 'CTAS-D_300s.csv']:\n",
        "    csv_path = results_dir / csv_file\n",
        "    if csv_path.exists():\n",
        "        df = pd.read_csv(csv_path)\n",
        "        print(f\"\\n{csv_file}:\")\n",
        "        print(f\"   Success Rate: {df['success_rate'].mean()*100:.1f}%\")\n",
        "        print(f\"   Avg Makespan: {df['makespan'].mean():.2f}\")\n",
        "\n",
        "# Our results\n",
        "final_metrics = evaluate(model, test_loader, device)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üìä OUR RESULTS (PoT CoalitionHybridHRM)\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nüéØ Coalition Accuracy: {final_metrics['coalition_acc']*100:.1f}%\")\n",
        "print(f\"üìè Size Match: {final_metrics['size_match']*100:.1f}%\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üìã COMPARISON\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\n{'Method':<25} {'Metric':>20}\")\n",
        "print(\"-\"*50)\n",
        "print(f\"{'REINFORCE_LF (paper)':<25} {'100% success, 34.8 makespan':>20}\")\n",
        "print(f\"{'OR-Tools (paper)':<25} {'100% success, 42.0 makespan':>20}\")\n",
        "print(f\"{'Ours (PoT)':<25} {f'{final_metrics[\"coalition_acc\"]*100:.1f}% coalition acc':>20}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Note: Paper reports success_rate and makespan (routing metric).\")\n",
        "print(\"We report coalition accuracy (correct robot selection).\")\n",
        "print(\"=\"*60)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6268ce987ed1427db079803969576b53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6a6f4e10612b4bf985ac310d66ce005f",
              "IPY_MODEL_ab8c714b3bc54febbde13ec38cef72e1",
              "IPY_MODEL_1f4fbed2eac74561918aefa9672d43a8"
            ],
            "layout": "IPY_MODEL_538da1ff4b22448d9147d9f1a6e7d4f8"
          }
        },
        "6a6f4e10612b4bf985ac310d66ce005f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd73307c44fa4b01826a98d42193667e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ac609466b57545aba2281eb92ad84264",
            "value": "Loading‚ÄáDCMRTA:‚Äá100%"
          }
        },
        "ab8c714b3bc54febbde13ec38cef72e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c7b1f365054482293294b2568da31a3",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_62e78ddc1c7d419ab595c1e8401437ad",
            "value": 50
          }
        },
        "1f4fbed2eac74561918aefa9672d43a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_195fdbe2083a401d8bcce4d1e5f6ce62",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_bcc4ccce265a4f94bf17e3e78e8bb3ec",
            "value": "‚Äá50/50‚Äá[00:00&lt;00:00,‚Äá155.12it/s]"
          }
        },
        "538da1ff4b22448d9147d9f1a6e7d4f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd73307c44fa4b01826a98d42193667e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac609466b57545aba2281eb92ad84264": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c7b1f365054482293294b2568da31a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62e78ddc1c7d419ab595c1e8401437ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "195fdbe2083a401d8bcce4d1e5f6ce62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcc4ccce265a4f94bf17e3e78e8bb3ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}